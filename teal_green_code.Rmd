---
title: "SPPH604: Polypharmacy & Mortality â€“ Reproducible Analyses"
author: "Teal Green (Alexi, Alex, Ezra)"
date: "`r format(Sys.Date())`"
output:
  html_document:
    df_print: paged
  pdf_document:
    latex_engine: xelatex
    keep_tex: false
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.pos = 'H'
)
set.seed(604)

# Suppress package loading messages
suppressMessages(suppressWarnings({
  library(tidyverse)
  library(survey)
  library(survival)
  library(gtsummary)
  library(gt)
  library(broom)
  library(mice)
  library(mitools)
  library(naniar)
  library(ggplot2)
  library(scales)
  library(DataExplorer)
  library(splines)
  library(car)
  library(forcats)
  library(stringr)
  library(kableExtra)
  library(patchwork)
}))

options(survey.lonely.psu = "adjust")
```

# Overview

This document analyzes the association between levels of prescription medication use and all-cause mortality among U.S. adults aged 45 years and older in NHANES 2003â€“2018. We follow NHANES analytic guidance (design first â†’ subset â†’ analyze), handle missingness in key covariates with multiple imputation, and fit/pool survey-weighted Cox models. We also include spline sensitivity analyses, interaction models with therapeutic classes, and several robustness checks (censoring, multimorbidity restrictions).

**Research question.** Among U.S. adults aged 45+ in NHANES 2003â€“2018, are different levels of medication use (0, 1â€“4, 5â€“9, â‰¥10) associated with all-cause mortality?

**PICOT**

**Population:** U.S. adults aged â‰¥45 in NHANES 2003â€“2018

**Intervention/exposure:** polypharmacy level (by interview-reported medication count)

**Comparator:** 1â€“4 medications

**Outcome:** time to all-cause mortality (linked mortality files through 2019)

**Timeframe:** up to \~17 years follow-up

**Covariates (a priori):** age, sex, race/ethnicity, education, income-to-poverty ratio, insurance, comorbidity burden (count + Charlson-like), health care utilization (visits, hospital stays), survey design.

We deliberately:

1.  **Do descriptive tables before imputation** and treat missing income and missing insurance as categories so they appear in the tables.

2.  **Assess missingness patterns** through visualization and logistic regression models to evaluate the assumption of missing at random (MAR).

3.  Then **impute both income-to-poverty ratio and insurance** using all analysis variables + survey design vars + a Nelsonâ€“Aalen cumulative hazard (so the outcome informs the imputation), following White & Royston (2009).

4.  Then **fit the main Cox models** across imputations and pool with Rubin's rules.

5.  **Check model diagnostics** including multicollinearity through variance inflation factors.

## Packages

```{r packages, eval=FALSE}
library(tidyverse)
library(survey)
library(survival)
library(gtsummary)
library(gt)
library(broom)
library(mice)
library(mitools)
library(naniar)
library(ggplot2)
library(scales)
library(DataExplorer)
library(splines)
library(car)
library(forcats)
library(stringr)
library(kableExtra)
library(patchwork)

options(survey.lonely.psu = "adjust")
```

## Load analytic dataset & survey design

We begin by loading our cleaned dataset and constructing the survey design object that accounts for NHANES' complex sampling structure.

```{r load-data}
# 1) Load dataset created in data_clean.R (provided separately)
# NOTE: Ensure the cleaning script has been run so analytic_raw.rds contains 'poly_cat_no_abx'
analytic_raw <- readRDS("data/analytic_raw.rds")

# 2) Create pooled interview weight over 8 cycles
analytic_raw <- analytic_raw %>%
    mutate(wtint_pool = wtint2yr / 8)

# 3) Set up survey design on the full dataset
dsgn_all <- svydesign(
  ids     = ~ sdmvpsu,
  strata  = ~ sdmvstra,
  weights = ~ wtint_pool,
  nest    = TRUE,
  data    = analytic_raw
)

# 4) Eligibility: age â‰¥ 45, non-missing survival time/event
dsgn_elig <- subset(
  dsgn_all,
  !is.na(ridageyr) & ridageyr >= 45 &
    !is.na(time_y) &
    event %in% c(0, 1) &
     !ucod_leading %in% c(4, 10)
)

# 5) Add model-ready variables to the survey design
# We explicitly set reference levels for both the main polypharmacy variable
# and the sensitivity variable (no antibiotics).
dsgn_elig <- update(
  dsgn_elig,
  age_years = ridageyr,
  age_cat   = factor(case_when(
    ridageyr >= 45 & ridageyr < 65 ~ "45-64",
    ridageyr >= 65 & ridageyr < 80 ~ "65-79",
    ridageyr >= 80                 ~ "80 or above"
  ), levels = c("45-64","65-79","80 or above")),
  poly_cat  = factor(poly_cat, levels = c("1â€“4","0","5â€“9","â‰¥10")),
  poly_cat_no_abx = factor(poly_cat_no_abx, levels = c("1â€“4","0","5â€“9","â‰¥10"))
)

# 6) Extract an ordinary data.frame for some steps
elig_df <- dsgn_elig$variables
glimpse(elig_df)
```

# **Descriptive statistics (pre-imputation, missing shown as category)**

We first describe the sample as observed, without imputation, so that missing income and missing insurance appear explicitly. This approach allows us to transparently report the extent of missingness in our key socioeconomic variables before applying multiple imputation techniques.

```{r descriptives-pre-mi}
# Recode missing income and missing insurance as their own categories
desc_df <- elig_df %>%
  mutate(
    indfmpir_cat_obs = case_when(
      is.na(indfmpir)              ~ "Missing",
      indfmpir < 1                 ~ "<1.00 (below poverty)",
      indfmpir >= 1 & indfmpir < 2 ~ "1.00â€“1.99",
      indfmpir >= 2 & indfmpir < 4 ~ "2.00â€“3.99",
      indfmpir >= 4                ~ "â‰¥4.00"
    ),
    indfmpir_cat_obs = factor(
      indfmpir_cat_obs,
      levels = c("<1.00 (below poverty)", "1.00â€“1.99", "2.00â€“3.99", "â‰¥4.00", "Missing")
    ),
    insured_obs = case_when(
      is.na(insured)   ~ "Missing/Unknown",
      insured == "Yes" ~ "Yes",
      insured == "No"  ~ "No",
      TRUE             ~ "Missing/Unknown"
    ),
    insured_obs = factor(insured_obs, levels = c("No","Yes","Missing/Unknown")),
    poly_cat = factor(poly_cat, levels = c("1â€“4","0","5â€“9","â‰¥10"))
  )

desc_design <- svydesign(
  ids     = ~ sdmvpsu,
  strata  = ~ sdmvstra,
  weights = ~ wtint_pool,
  nest    = TRUE,
  data    = desc_df
)

cont_vars   <- c("rxdcount","comorbidity_n","cci_score")
n_overall   <- nrow(desc_df)
n_by_poly   <- table(desc_df$poly_cat)
poly_levels <- levels(desc_df$poly_cat)

# Continuous (survey-weighted)
tbl_cont_exposure <- gtsummary::tbl_svysummary(
  data      = desc_design,
  by        = poly_cat,
  include   = all_of(cont_vars),
  statistic = list(gtsummary::all_continuous() ~ "{mean} ({sd})"),
  missing   = "no",
  label     = list(
    rxdcount      ~ "Medication count",
    comorbidity_n ~ "Number of comorbidities",
    cci_score     ~ "Charlson-like comorbidity score"
  )
) %>%
  gtsummary::add_overall() %>%
  gtsummary::bold_labels()

for (i in seq_along(poly_levels)) {
  tbl_cont_exposure <- tbl_cont_exposure %>%
    gtsummary::modify_header(
      !!paste0("stat_", i) :=
        paste0("**", poly_levels[i], "** \nN = ", format(n_by_poly[poly_levels[i]], big.mark = ","))
    )
}
tbl_cont_exposure <- tbl_cont_exposure %>%
  gtsummary::modify_header(
    stat_0 ~ paste0("**Overall** \nN = ", format(n_overall, big.mark = ","))
  )

# Categorical (unweighted n, weighted % conceptually but we keep unweighted counts here)
tbl_cat_exposure <- gtsummary::tbl_summary(
  data     = desc_df,
  by       = poly_cat,
  include  = c(
    "event","age_cat","sex","race_eth","ed_cat",
    "indfmpir_cat_obs","insured_obs","visits_cat","hosp_stays_cat"
  ) %>% intersect(names(desc_df)),
  statistic = list(gtsummary::all_categorical() ~ "{n} ({p}%)"),
  missing   = "no",
  label     = list(
    event            ~ "Mortality status",
    age_cat          ~ "Age group",
    sex              ~ "Sex",
    race_eth         ~ "Race/ethnicity",
    ed_cat           ~ "Education",
    indfmpir_cat_obs ~ "Income-to-poverty ratio",
    insured_obs      ~ "Insurance coverage",
    visits_cat       ~ "Doctor visits in past year",
    hosp_stays_cat   ~ "Hospital stays in past year"
  )
) %>%
  gtsummary::add_overall(last = TRUE) %>%
  gtsummary::bold_labels()

for (i in seq_along(poly_levels)) {
  tbl_cat_exposure <- tbl_cat_exposure %>%
    gtsummary::modify_header(
      !!paste0("stat_", i) :=
        paste0("**", poly_levels[i], "** \nN = ", format(n_by_poly[poly_levels[i]], big.mark = ","))
    )
}
tbl_cat_exposure <- tbl_cat_exposure %>%
  gtsummary::modify_header(
    stat_0 ~ paste0("**Overall** \nN = ", format(n_overall, big.mark = ","))
  )

gtsummary::tbl_stack(list(tbl_cont_exposure, tbl_cat_exposure)) %>%
  gtsummary::modify_caption("**Descriptive statistics by polypharmacy (observed; missing income/insurance shown as categories)**")
```

## **Descriptive statistics by outcome status**

We also present sample characteristics stratified by vital status at the end of follow-up to examine differences between those who survived and those who died during follow-up.

```{r descriptives-by-outcome}
# Create a factor version of event for better labeling
desc_df <- desc_df %>%
  mutate(
    event_factor = factor(event, 
                         levels = c(0, 1), 
                         labels = c("Alive/Censored", "Deceased"))
  )

# Update survey design with the new factor
desc_design_outcome <- svydesign(
  ids     = ~ sdmvpsu,
  strata  = ~ sdmvstra,
  weights = ~ wtint_pool,
  nest    = TRUE,
  data    = desc_df
)

n_by_outcome <- table(desc_df$event_factor)
outcome_levels <- levels(desc_df$event_factor)

# Continuous variables (survey-weighted) by outcome
tbl_cont_outcome <- gtsummary::tbl_svysummary(
  data      = desc_design_outcome,
  by        = event_factor,
  include   = all_of(cont_vars),
  statistic = list(gtsummary::all_continuous() ~ "{mean} ({sd})"),
  missing   = "no",
  label     = list(
    rxdcount      ~ "Medication count",
    comorbidity_n ~ "Number of comorbidities",
    cci_score     ~ "Charlson-like comorbidity score"
  )
) %>%
  gtsummary::add_overall() %>%
  gtsummary::bold_labels()

for (i in seq_along(outcome_levels)) {
  tbl_cont_outcome <- tbl_cont_outcome %>%
    gtsummary::modify_header(
      !!paste0("stat_", i) :=
        paste0("**", outcome_levels[i], "** \nN = ", format(n_by_outcome[outcome_levels[i]], big.mark = ","))
    )
}
tbl_cont_outcome <- tbl_cont_outcome %>%
  gtsummary::modify_header(
    stat_0 ~ paste0("**Overall** \nN = ", format(n_overall, big.mark = ","))
  )

# Categorical variables by outcome (excluding event itself)
tbl_cat_outcome <- gtsummary::tbl_summary(
  data     = desc_df,
  by       = event_factor,
  include  = c(
    "poly_cat","age_cat","sex","race_eth","ed_cat",
    "indfmpir_cat_obs","insured_obs","visits_cat","hosp_stays_cat"
  ) %>% intersect(names(desc_df)),
  statistic = list(gtsummary::all_categorical() ~ "{n} ({p}%)"),
  missing   = "no",
  label     = list(
    poly_cat         ~ "Polypharmacy category",
    age_cat          ~ "Age group",
    sex              ~ "Sex",
    race_eth         ~ "Race/ethnicity",
    ed_cat           ~ "Education",
    indfmpir_cat_obs ~ "Income-to-poverty ratio",
    insured_obs      ~ "Insurance coverage",
    visits_cat       ~ "Doctor visits in past year",
    hosp_stays_cat   ~ "Hospital stays in past year"
  )
) %>%
  gtsummary::add_overall(last = TRUE) %>%
  gtsummary::bold_labels()

for (i in seq_along(outcome_levels)) {
  tbl_cat_outcome <- tbl_cat_outcome %>%
    gtsummary::modify_header(
      !!paste0("stat_", i) :=
        paste0("**", outcome_levels[i], "** \nN = ", format(n_by_outcome[outcome_levels[i]], big.mark = ","))
    )
}
tbl_cat_outcome <- tbl_cat_outcome %>%
  gtsummary::modify_header(
    stat_0 ~ paste0("**Overall** \nN = ", format(n_overall, big.mark = ","))
  )

gtsummary::tbl_stack(list(tbl_cont_outcome, tbl_cat_outcome)) %>%
  gtsummary::modify_caption("**Descriptive statistics by vital status (observed; missing income/insurance shown as categories)**")
```

\\newpage

# Kaplanâ€“Meier curves by polypharmacy + log-rank test

We present weighted Kaplan-Meier survival curves stratified by polypharmacy category to visualize crude survival patterns over follow-up time, accompanied by a risk table showing the unweighted number of participants at risk.

```{r km-curves, fig.width=8, fig.height=8, fig.cap="Kaplan-Meier survival curves by polypharmacy category with risk table"}
# ---- Survey-weighted Kaplanâ€“Meier by polypharmacy (full time; no SE/CI) -----
dd_km <- svydesign(
  ids     = ~ sdmvpsu,
  strata  = ~ sdmvstra,
  weights = ~ wtint_pool,
  nest    = TRUE,
  data    = desc_df
)

km_fit <- svykm(Surv(time_y, event) ~ poly_cat, design = dd_km, se = FALSE, ci = FALSE)

km_df <- purrr::imap_dfr(km_fit, function(fit, grp) {
  tibble(
    time     = fit$time,
    surv     = fit$surv,
    poly_cat = grp
  )
})

# 1) Main KM Plot
p_km <- ggplot(km_df, aes(x = time, y = surv, color = poly_cat)) +
  geom_step(linewidth = 0.9) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1)) +
  labs(
    title = "Survey-weighted Kaplanâ€“Meier survival",
    x     = "Years since interview",
    y     = "Survival probability",
    color = "Medication use"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    panel.grid.minor = element_blank(),
    legend.position = "top",
    axis.title.x = element_blank(), # remove X title to stack with table
    axis.text.x = element_blank()   # remove X text to stack with table
  )

# 2) Create Data for Risk Table (Unweighted counts using standard survfit)
#    Note: Risk tables typically show unweighted N to indicate data sparsity
risk_times <- c(0, 4, 8, 12, 16)
fit_unweighted <- survfit(Surv(time_y, event) ~ poly_cat, data = desc_df)

risk_data <- summary(fit_unweighted, times = risk_times, extend = TRUE)
risk_tbl_df <- tibble(
  time = risk_data$time,
  n.risk = risk_data$n.risk,
  strata = as.character(risk_data$strata)
) %>%
  mutate(
    poly_cat = str_remove(strata, "poly_cat=")
  )

# 3) Create Risk Table Plot
p_table <- ggplot(risk_tbl_df, aes(x = time, y = poly_cat, label = n.risk)) +
  geom_text(size = 3.5) +
  labs(x = "Years since interview", y = NULL) +
  scale_x_continuous(breaks = risk_times) +
  theme_minimal(base_size = 12) +
  theme(
    panel.grid = element_blank(),
    axis.text.y = element_text(face = "bold", hjust = 1)
  )

# 4) Stack them
# layout: KM plot on top (3 parts height), Table on bottom (1 part height)
p_km / p_table + plot_layout(heights = c(4, 1))

# design-based omnibus test (via Cox + regTermTest)
fit_lr  <- svycoxph(Surv(time_y, event) ~ poly_cat, design = dd_km)
omni    <- regTermTest(fit_lr, ~ poly_cat)

knitr::kable(
  tibble(
    test = "Design-based log-rank (via Cox/regTermTest)",
    F    = omni$Ftest,
    df1  = omni$df[1],
    df2  = omni$df[2],
    p    = omni$p
  ),
  digits = 4,
  caption = "Omnibus design-based test of equality of survival functions across medication-use categories"
)
```

\\newpage

# **Missingness review (post-eligibility)**

Before proceeding with multiple imputation, we systematically assess patterns of missingness in our key variables. We focus particularly on income-to-poverty ratio (INDFMPIR) and insurance status (INSURED), as these socioeconomic variables often exhibit complex patterns of non-response. We use both visual inspection and logistic regression models to test whether missingness is associated with observed characteristicsâ€”a key assumption for multiple imputation under the missing at random (MAR) framework.

```{r missingness-review}
# Define variables to assess for missingness
miss_vars <- c(
  "indfmpir","insured","age_years","sex","race_eth","ed_cat",
  "comorbidity_n","cci_score","visits_cat","hosp_stays_cat"
)

# Variable-wise missingness summary (counts & %)
miss_summary <- elig_df %>%
  miss_var_summary(include = dplyr::all_of(miss_vars))

knitr::kable(
  miss_summary,
  digits = 2,
  caption = "Variable-wise missingness summary"
) %>%
  kableExtra::kable_styling()

# Visual missingness plot
plot_missing(elig_df[, miss_vars])

# Create missingness indicators for further analysis
elig_df <- elig_df %>%
  mutate(
    miss_indfmpir = factor(ifelse(is.na(indfmpir), "Missing","Observed")),
    miss_insured  = factor(ifelse(is.na(insured),  "Missing","Observed"))
  )
```

## Logistic regression models for missingness

We fit logistic regression models to predict missingness in income-to-poverty ratio and insurance status. These models help us understand whether missingness is related to other observed characteristics (supporting the MAR assumption) or appears completely at random (MCAR). Significant associations between missingness and observed covariates suggest that our imputation model should include these predictors to properly account for the missingness mechanism.

For income-to-poverty ratio, we include all analysis variables except the variable itself. For insurance status, we similarly include all other analysis variables. This comprehensive approach ensures our imputation model captures the relationships between missingness and observed data.

```{r missingness-logistic}
# Logistic model for INDFMPIR missingness
# We include all variables that will be used in the imputation model
fit_miss_indf <- glm(
  I(is.na(indfmpir)) ~ 
    age_years + sex + race_eth + ed_cat + insured + 
    comorbidity_n + cci_score + visits_cat + hosp_stays_cat +
    poly_cat + rxdcount,
  data = elig_df, 
  family = binomial()
)

# Logistic model for INSURED missingness
fit_miss_ins <- glm(
  I(is.na(insured)) ~ 
    age_years + sex + race_eth + ed_cat + indfmpir + 
    comorbidity_n + cci_score + visits_cat + hosp_stays_cat +
    poly_cat + rxdcount,
  data = elig_df, 
  family = binomial()
)

# Display results for INDFMPIR missingness model
indf_miss_tbl <- broom::tidy(fit_miss_indf, exponentiate = TRUE, conf.int = TRUE) %>%
  dplyr::mutate(dplyr::across(where(is.numeric), ~round(., 3))) %>%
  dplyr::select(term, estimate, conf.low, conf.high, p.value)

knitr::kable(
  indf_miss_tbl,
  caption = "Logistic regression for INDFMPIR missingness (odds ratios)"
) %>%
  kableExtra::kable_styling()

# Display results for INSURED missingness model
ins_miss_tbl <- broom::tidy(fit_miss_ins, exponentiate = TRUE, conf.int = TRUE) %>%
  dplyr::select(term, estimate, conf.low, conf.high, p.value)

knitr::kable(
  ins_miss_tbl,
  caption = "Logistic regression for INSURED missingness (odds ratios)"
) %>%
  kableExtra::kable_styling()
```

**Interpretation:** The logistic regression models reveal that missingness in both INDFMPIR and INSURED is systematically associated with observed demographic and health characteristics, rejecting the missing completely at random (MCAR) assumption. For INDFMPIR, we observe significant associations with age, race/ethnicity, education, insurance status, and healthcare utilization patterns. Similarly, insurance missingness varies significantly by age, race/ethnicity, education, and income level. These patterns support the missing at random (MAR) assumption, conditional on observed covariates, justifying our multiple imputation approach. We proceed with multiple imputation using all observed predictors, including a Nelson-Aalen cumulative hazard term to incorporate information from the survival outcome as recommended by White & Royston (2009).

\\newpage

# **Multiple imputation (indfmpir, insured) with Nelsonâ€“Aalen hazard**

We now build an imputation model that:

  - imputes **both** income-to-poverty ratio (indfmpir) using predictive mean matching (PMM) and insurance (insured) using logistic regression;

  - includes the **survey design** variables (PSU, strata, weight) so they are available downstream;

  - includes a **Nelsonâ€“Aalen cumulative hazard** built from the observed survival, as recommended by White & Royston (2009) to ensure the outcome informs the imputation process.

The Nelson-Aalen cumulative hazard captures information about the survival outcome without requiring event/censoring indicators to be included as predictors directly. This approach has been shown to reduce bias when imputing covariates in survival analyses.

```{r mi-nelson-aalen}
# Overall (unweighted) Nelsonâ€“Aalen from the eligible sample
sf_all  <- survfit(Surv(time_y, event) ~ 1, data = elig_df)
na_fun  <- stepfun(sf_all$time, c(0, sf_all$cumhaz))

elig_df <- elig_df %>%
  mutate(
    na_cumhaz = na_fun(time_y)
  )
```

```{r mi-run}
## 1) Build imputation-ready data ----
mi_dat <- elig_df %>%
  mutate(
    # make insurance strictly binary for MI
    insured = case_when(
      insured == "Yes" ~ "Yes",
      insured == "No"  ~ "No",
      TRUE             ~ NA_character_
    ),
    insured = factor(insured, levels = c("No","Yes"))
  ) %>%
  transmute(
    seqn,
    sdmvpsu, sdmvstra, wtint_pool,     # survey design vars
    time_y, event, na_cumhaz,          # survival info
    rxdcount,
    poly_cat,
    poly_cat_no_abx,                   # <--- Variable that caused previous error
    ridageyr,
    age_cat,
    sex,
    race_eth,
    ed_cat,
    indfmpir,
    insured,
    comorbidity_n,
    cci_score,
    visits_cat,
    hosp_stays_cat,
    rx_antineoplastic,
    rx_cns,
    rx_cardiovascular,
    rx_psychotherapeutic
  )

## 2) Methods & predictor matrix ----
meth <- make.method(mi_dat)
pred <- make.predictorMatrix(mi_dat)

# start from: "impute nothing"
meth[] <- ""

# we only want to impute these two:
meth["indfmpir"] <- "pmm"
meth["insured"]  <- "logreg"

# allow all vars to help predict, but:
# - design vars should be available as predictors
# - they themselves are not imputed
pred[] <- 0

# indfmpir uses (almost) everything
pred["indfmpir", ] <- 1
# but not itself
pred["indfmpir", "indfmpir"] <- 0

# insured uses (almost) everything
pred["insured", ] <- 1
pred["insured", "insured"] <- 0

# we do NOT impute these:
no_impute <- c("seqn","sdmvpsu","sdmvstra","wtint_pool","time_y","event","na_cumhaz")
meth[no_impute] <- ""
# they can still be used as predictors, so we keep pred[...] = 1 for rows above

## 3) Run MI ----
# We use m=20 imputations and maxit=20 iterations to ensure convergence
imp <- mice(
  mi_dat,
  m       = 20,
  maxit   = 20,
  method  = meth,
  predictorMatrix = pred,
  seed    = 604,
  printFlag = FALSE  # Suppress iteration messages
)

# Quick visual check of convergence
plot(imp, c("indfmpir","insured"))
```

\\newpage

# **Helper functions**

We define helper functions to consistently categorize age and income-to-poverty ratio across all model specifications. This ensures reproducibility and reduces coding errors.

```{r helpers}
mk_age_cat <- function(ridageyr) {
  factor(case_when(
    ridageyr >= 45 & ridageyr < 65 ~ "45-64",
    ridageyr >= 65 & ridageyr < 80 ~ "65-79",
    ridageyr >= 80                 ~ "80 or above"
  ), levels = c("45-64","65-79","80 or above"))
}

mk_indfmpir_cat <- function(x) {
  factor(case_when(
    is.na(x)              ~ NA_character_,
    x < 1                 ~ "<1.00 (below poverty)",
    x >= 1 & x < 2        ~ "1.00â€“1.99",
    x >= 2 & x < 4        ~ "2.00â€“3.99",
    x >= 4                ~ "â‰¥4.00"
  ), levels = c("<1.00 (below poverty)","1.00â€“1.99","2.00â€“3.99","â‰¥4.00"))
}
```

\\newpage

# **Main Cox models (crude & full)**

We fit two Cox proportional hazards models to examine the association between polypharmacy and all-cause mortality. The crude model includes only the exposure variable, and the full model includes all a priori confounders including socioeconomic status, comorbidity burden, and healthcare utilization. All models use survey weights and account for the complex survey design. We use Rubin's rules to pool estimates across the 20 imputed datasets.

```{r cox-main}
# Crude model: exposure only
fit_crude <- with(imp, {
  di <- tibble(
    sdmvpsu, sdmvstra, wtint_pool, time_y, event,
    poly_cat = factor(poly_cat, levels = c("1â€“4","0","5â€“9","â‰¥10"))
  )
  dd <- svydesign(ids = ~sdmvpsu, strata = ~sdmvstra, weights = ~wtint_pool,
                  nest = TRUE, data = di)
  svycoxph(Surv(time_y, event) ~ poly_cat, design = dd)
})

# Full model: add all confounders
fit_full <- with(imp, {
  di <- tibble(
    sdmvpsu, sdmvstra, wtint_pool, time_y, event,
    poly_cat = factor(poly_cat, levels = c("1â€“4","0","5â€“9","â‰¥10")),
    age_cat  = mk_age_cat(ridageyr),
    sex, race_eth, ed_cat,
    insured  = factor(insured, levels = c("No","Yes")),
    indfmpir, indfmpir_cat = mk_indfmpir_cat(indfmpir),
    comorbidity_n = as.numeric(comorbidity_n),
    cci_score     = as.numeric(cci_score),
    visits_cat, hosp_stays_cat
  ) %>%
    mutate(across(where(is.factor), fct_drop))
  dd <- svydesign(ids = ~sdmvpsu, strata = ~sdmvstra, weights = ~wtint_pool,
                  nest = TRUE, data = di)
  svycoxph(
    Surv(time_y, event) ~ poly_cat + age_cat + sex + race_eth +
      ed_cat + indfmpir_cat + insured + comorbidity_n + cci_score +
      visits_cat + hosp_stays_cat,
    design = dd
  )
})

labels_full <- list(
  poly_cat       ~ "Polypharmacy",
  age_cat        ~ "Age group",
  sex            ~ "Sex",
  race_eth       ~ "Race/ethnicity",
  ed_cat         ~ "Education",
  indfmpir_cat   ~ "Income-to-poverty ratio",
  insured        ~ "Insurance coverage",
  comorbidity_n  ~ "Number of comorbidities",
  cci_score      ~ "Charlson-like comorbidity index",
  visits_cat     ~ "Doctor visits in past year",
  hosp_stays_cat ~ "Hospital stays in past year"
)

# Suppress gtsummary messages
sink(tempfile())
tbl_crude <- gtsummary::tbl_regression(fit_crude,
                                       exponentiate = TRUE,
                                       label = list(poly_cat ~ "Polypharmacy")) %>%
  gtsummary::bold_labels()

tbl_full <- gtsummary::tbl_regression(fit_full,
                                      exponentiate = TRUE,
                                      label = labels_full) %>%
  gtsummary::bold_labels()
sink()

tbl_combined <- gtsummary::tbl_merge(
  tbls = list(tbl_crude, tbl_full),
  tab_spanner = c("**Crude model**","**Full model**")
) %>%
  gtsummary::modify_caption("**Survey-weighted Cox proportional hazards models for all-cause mortality (MI pooled)**") %>%
  gtsummary::modify_footnote(
    update = gtsummary::all_stat_cols() ~
      "HR = hazard ratio; CI = confidence interval. Reference category for polypharmacy is 1â€“4 medications."
  )

tbl_combined %>%
  gtsummary::as_gt()

```

\\newpage

# **Cox model diagnostics: PH assumption & Multicollinearity**

## Proportional Hazards Assumption

To assess the Proportional Hazards (PH) assumption, we use an ad-hoc diagnostic approach recommended for complex survey data where standard tests are not natively supported. We extract a single imputed dataset (Imputation \#1) and fit a standard Cox model incorporating the survey weights to calculate Scaled Schoenfeld Residuals. While this approach does not fully account for the complex survey design in the variance estimation of the test itself, visual inspection of the residuals provides a robust diagnostic for deviations from the PH assumption.

```{r cox-diagnostics-ph, fig.width=8, fig.height=6}
# Ad-hoc PH test using Imputation #1 and weighted coxph
# Extract completed data from imputation #1
d1_ph <- mice::complete(imp, 1) %>%
  mutate(
    # Ensure identical factor levels as in the Cox model
    poly_cat       = factor(poly_cat, levels = c("1â€“4","0","5â€“9","â‰¥10")) %>% forcats::fct_drop(),
    age_cat        = mk_age_cat(ridageyr) %>% forcats::fct_drop(),
    sex            = factor(sex) %>% forcats::fct_drop(),
    race_eth       = factor(race_eth) %>% forcats::fct_drop(),
    ed_cat         = factor(ed_cat) %>% forcats::fct_drop(),
    indfmpir_cat   = mk_indfmpir_cat(indfmpir) %>% forcats::fct_drop(),
    insured        = factor(insured, levels = c("No","Yes")) %>% forcats::fct_drop(),
    visits_cat     = factor(visits_cat) %>% forcats::fct_drop(),
    hosp_stays_cat = factor(hosp_stays_cat) %>% forcats::fct_drop(),
    comorbidity_n  = as.numeric(comorbidity_n),
    cci_score      = as.numeric(cci_score)
  )

# Fit standard coxph with weights
fit_ph_check <- coxph(
  Surv(time_y, event) ~ poly_cat + age_cat + sex + race_eth +
      ed_cat + indfmpir_cat + insured + comorbidity_n + cci_score +
      visits_cat + hosp_stays_cat,
  data = d1_ph,
  weights = wtint_pool,
  robust = TRUE # robust variance helps slightly with weighting
)

# Calculate Schoenfeld residuals
zph_res <- cox.zph(fit_ph_check)

# Plot residuals for the main exposure (poly_cat)
plot(zph_res, var = "poly_cat")
```

## Multicollinearity Assessment

Before interpreting our Cox model results, we assess multicollinearity among predictors using variance inflation factors (VIF). High multicollinearity can inflate standard errors and make coefficient estimates unstable. We use generalized VIF (GVIF) which is appropriate for models with categorical predictors. For multi-degree-of-freedom terms, we report the adjusted GVIF: GVIF^(1/(2Ã—Df)), which is comparable to standard VIF for continuous predictors.

Following convention, we use imputation \#1 to construct an auxiliary weighted linear model with the same predictor structure as our full Cox model. The VIF values are computed from this linear model and apply to the predictor relationships in our Cox model.

```{r cox-diagnostics-vif}
# Extract completed data from imputation #1
d1 <- mice::complete(imp, 1) %>%
  mutate(
    # Ensure identical factor levels as in the Cox model
    poly_cat       = factor(poly_cat, levels = c("1â€“4","0","5â€“9","â‰¥10")) %>% forcats::fct_drop(),
    age_cat        = mk_age_cat(ridageyr) %>% forcats::fct_drop(),
    sex            = factor(sex) %>% forcats::fct_drop(),
    race_eth       = factor(race_eth) %>% forcats::fct_drop(),
    ed_cat         = factor(ed_cat) %>% forcats::fct_drop(),
    indfmpir_cat   = mk_indfmpir_cat(indfmpir) %>% forcats::fct_drop(),
    insured        = factor(insured, levels = c("No","Yes")) %>% forcats::fct_drop(),
    visits_cat     = factor(visits_cat) %>% forcats::fct_drop(),
    hosp_stays_cat = factor(hosp_stays_cat) %>% forcats::fct_drop(),
    comorbidity_n  = as.numeric(comorbidity_n),
    cci_score      = as.numeric(cci_score)
  )

# Create a dummy outcome for VIF calculation (VIF uses only the predictor matrix)
set.seed(604)
y_dummy <- rnorm(nrow(d1))

# Fit auxiliary weighted linear model with the exact same RHS as the full Cox model
aux_lm <- lm(
  y_dummy ~ poly_cat + age_cat + sex + race_eth + ed_cat + indfmpir_cat +
    insured + comorbidity_n + cci_score + visits_cat + hosp_stays_cat,
  data    = d1,
  weights = wtint_pool
)

# Calculate GVIF/GVIF^(1/(2*Df))
gv <- car::vif(aux_lm)

gvif_df <-
  if (is.matrix(gv)) {
    # Multi-df terms present (categorical variables)
    as.data.frame(gv) %>%
      tibble::rownames_to_column("Variable") %>%
      dplyr::rename(GVIF = GVIF, Df = Df) %>%
      dplyr::mutate(`Adj.GVIF` = GVIF^(1/(2*Df)))
  } else {
    # All 1-df terms (continuous variables only)
    tibble::tibble(
      Variable = names(gv),
      GVIF     = as.numeric(gv),
      Df       = 1L,
      `Adj.GVIF` = sqrt(GVIF)
    )
  } %>%
  dplyr::mutate(
    Severity = dplyr::case_when(
      `Adj.GVIF` > 5    ~ "ðŸš¨ severe",
      `Adj.GVIF` > 2.5  ~ "âš  high",
      `Adj.GVIF` > 2.0  ~ "~ moderate",
      TRUE              ~ "âœ“ low"
    )
  )

knitr::kable(
  gvif_df,
  digits  = 3,
  caption = "Variance inflation factors for full Cox model (based on imputation #1)"
) %>%
  kableExtra::kable_styling()
```

**Interpretation:** We assess multicollinearity using adjusted GVIF values. For categorical predictors, the adjusted GVIF (GVIF^(1/(2Ã—Df))) provides a measure comparable to standard VIF for continuous variables. Values above 5 indicate severe multicollinearity, values between 2.5-5 suggest high multicollinearity, and values between 2-2.5 indicate moderate multicollinearity. Our results show that all adjusted GVIF values are within acceptable ranges (\< 5), indicating that multicollinearity is not a substantial concern in our model. Some moderate correlations among socioeconomic variables (education, income, insurance) are expected and do not compromise the validity of our estimates. The model's predictor structure is appropriate for drawing inferences about the association between polypharmacy and mortality.

\\newpage

# **Interaction models with therapeutic classes**

To explore whether the association between polypharmacy and mortality differs by type of medication, we fit interaction models between polypharmacy categories and four major therapeutic classes: antineoplastic agents, central nervous system (CNS) medications, cardiovascular drugs, and psychotherapeutic medications. We visualize these interactions using a faceted plot to clearly separate the effects within each therapeutic class.

```{r interaction-models, fig.width=10, fig.height=8}
rx_flags <- c(
  "rx_antineoplastic",
  "rx_cns",
  "rx_cardiovascular",
  "rx_psychotherapeutic"
)

# ------------------------------------------------------------
# helper: tidy MIcombine output â†’ tibble with term column
# ------------------------------------------------------------
tidy_from_micombine <- function(mi_obj, exponentiate = TRUE) {
  sm <- summary(mi_obj, conf.int = TRUE)
  sm <- tibble::as_tibble(sm, rownames = "term")  # <-- make 'term'

  nm <- names(sm)
  lower_name <- nm[grepl("lower", nm, fixed = TRUE)]
  upper_name <- nm[grepl("upper", nm, fixed = TRUE)]

  if (length(lower_name) == 1) {
    sm <- dplyr::rename(sm, conf.low = !!lower_name)
  }
  if (length(upper_name) == 1) {
    sm <- dplyr::rename(sm, conf.high = !!upper_name)
  }

  sm <- dplyr::rename(sm, estimate = results, std.error = se)

  if (!"p.value" %in% names(sm)) {
    sm$p.value <- NA_real_
  }

  if (exponentiate) {
    sm <- sm %>%
      dplyr::mutate(
        estimate = exp(estimate),
        conf.low = exp(conf.low),
        conf.high = exp(conf.high)
      )
  }

  sm %>%
    dplyr::mutate(statistic = NA_real_) %>%
    dplyr::select(term, estimate, std.error, statistic, conf.low, conf.high, p.value)
}

# ------------------------------------------------------------
# fit interaction model for ONE class, excluding poly_cat == "0"
# ------------------------------------------------------------
fit_interaction_for_flag <- function(flag, imp_obj) {
  m <- imp_obj$m
  fit_list <- vector("list", m)
  keep     <- rep(FALSE, m)

  for (i in seq_len(m)) {
    di <- mice::complete(imp_obj, i)

    if (!flag %in% names(di)) {
      di[[flag]] <- 0L
    }

    di <- di %>%
      dplyr::filter(poly_cat != "0") %>%
      dplyr::mutate(
        poly_cat     = factor(poly_cat, levels = c("1â€“4","5â€“9","â‰¥10")),
        age_cat      = mk_age_cat(ridageyr),
        indfmpir_cat = mk_indfmpir_cat(indfmpir),
        insured      = factor(insured, levels = c("No","Yes")),
        class_flag_raw = dplyr::coalesce(!!rlang::sym(flag), 0L),
        class_flag     = factor(ifelse(class_flag_raw == 1, 1, 0), levels = c(0,1)),
        comorbidity_n  = as.numeric(comorbidity_n),
        cci_score      = as.numeric(cci_score)
      ) %>%
      dplyr::mutate(dplyr::across(where(is.factor), forcats::fct_drop))

    if (length(unique(di$class_flag)) < 2) {
      next
    }

    dd <- svydesign(
      ids     = ~ sdmvpsu,
      strata  = ~ sdmvstra,
      weights = ~ wtint_pool,
      nest    = TRUE,
      data    = di
    )

    fit_i <- try(
      svycoxph(
        survival::Surv(time_y, event) ~ poly_cat * class_flag +
          age_cat + sex + race_eth + ed_cat + indfmpir_cat + insured +
          comorbidity_n + cci_score + visits_cat + hosp_stays_cat,
        design = dd
      ),
      silent = TRUE
    )

    if (!inherits(fit_i, "try-error")) {
      fit_list[[i]] <- fit_i
      keep[i] <- TRUE
    }
  }

  if (!any(keep)) {
    stop("No usable imputations for ", flag, " (no variation in class_flag).")
  }

  coefs  <- lapply(fit_list[keep], coef)
  vcovs  <- lapply(fit_list[keep], vcov)
  pooled <- mitools::MIcombine(coefs, vcovs)

  list(
    pooled   = pooled,
    fits     = fit_list[keep],
    keep_ids = which(keep)
  )
}

# ------------------------------------------------------------
# interaction measures
# ------------------------------------------------------------
interaction_measures_from_pooled <- function(pooled_obj) {
  beta <- pooled_obj$coefficients
  V    <- pooled_obj$variance

  get_lhr <- function(term_vec) {
    b  <- beta[names(term_vec)]
    lh <- sum(b * term_vec)
    se <- sqrt(as.numeric(t(term_vec) %*%
                            V[names(term_vec), names(term_vec), drop = FALSE] %*%
                            term_vec))
    c(lhr = lh, se = se)
  }

  rows <- list()
  rows[["poly1_4_class0"]] <- c(lhr = 0, se = 0)

  if ("class_flag1" %in% names(beta)) {
    rows[["poly1_4_class1"]] <- get_lhr(c(class_flag1 = 1))
  }
  if ("poly_cat5â€“9" %in% names(beta)) {
    rows[["poly5_9_class0"]] <- get_lhr(c(`poly_cat5â€“9` = 1))
  }
  if (all(c("poly_cat5â€“9","class_flag1","poly_cat5â€“9:class_flag1") %in% names(beta))) {
    rows[["poly5_9_class1"]] <- get_lhr(c(
      `poly_cat5â€“9` = 1,
      class_flag1 = 1,
      `poly_cat5â€“9:class_flag1` = 1
    ))
  }
  if ("poly_catâ‰¥10" %in% names(beta)) {
    rows[["poly10p_class0"]] <- get_lhr(c(`poly_catâ‰¥10` = 1))
  }
  if (all(c("poly_catâ‰¥10","class_flag1","poly_catâ‰¥10:class_flag1") %in% names(beta))) {
    rows[["poly10p_class1"]] <- get_lhr(c(
      `poly_catâ‰¥10` = 1,
      class_flag1   = 1,
      `poly_catâ‰¥10:class_flag1` = 1
    ))
  }

  combos_df <- purrr::imap_dfr(rows, ~{
    tibble::tibble(
      combo = .y,
      logHR = .x[["lhr"]],
      se    = .x[["se"]],
      HR    = exp(.x[["lhr"]]),
      LCL   = exp(.x[["lhr"]] - 1.96 * .x[["se"]]),
      UCL   = exp(.x[["lhr"]] + 1.96 * .x[["se"]])
    )
  })

  add_mult_59 <- NULL
  if (all(c("poly5_9_class1","poly5_9_class0","poly1_4_class1") %in% combos_df$combo)) {
    HR11 <- combos_df$HR[combos_df$combo == "poly5_9_class1"]
    HR10 <- combos_df$HR[combos_df$combo == "poly5_9_class0"]
    HR01 <- combos_df$HR[combos_df$combo == "poly1_4_class1"]
    RERI <- HR11 - HR10 - HR01 + 1
    mult <- HR11 / (HR10 * HR01)
    add_mult_59 <- tibble::tibble(
      band = "5â€“9",
      RERI = RERI,
      mult = mult
    )
  }

  add_mult_10p <- NULL
  if (all(c("poly10p_class1","poly10p_class0","poly1_4_class1") %in% combos_df$combo)) {
    HR11 <- combos_df$HR[combos_df$combo == "poly10p_class1"]
    HR10 <- combos_df$HR[combos_df$combo == "poly10p_class0"]
    HR01 <- combos_df$HR[combos_df$combo == "poly1_4_class1"]
    RERI <- HR11 - HR10 - HR01 + 1
    mult <- HR11 / (HR10 * HR01)
    add_mult_10p <- tibble::tibble(
      band = "â‰¥10",
      RERI = RERI,
      mult = mult
    )
  }

  list(
    combos = combos_df,
    additive_multiplicative = dplyr::bind_rows(add_mult_59, add_mult_10p)
  )
}

# ------------------------------------------------------------
# run for all 4 therapeutic classes
# ------------------------------------------------------------
rx_flags <- c(
  "rx_antineoplastic",
  "rx_cns",
  "rx_cardiovascular",
  "rx_psychotherapeutic"
)

int_results <- purrr::map(rx_flags, ~fit_interaction_for_flag(.x, imp))
names(int_results) <- rx_flags

int_measures <- purrr::imap(int_results, function(obj, flag) {
  mm <- interaction_measures_from_pooled(obj$pooled)
  list(flag = flag, combos = mm$combos, im = mm$additive_multiplicative)
})

# ------------------------------------------------------------
# gtsummary tables (one per class)
# ------------------------------------------------------------
sink(tempfile())
int_tbls <- purrr::imap(int_results, function(x, flag) {
  td <- tidy_from_micombine(x$pooled, exponentiate = TRUE)
  dummy_fit <- x$fits[[1]]

  gtsummary::tbl_regression(
    x = dummy_fit,
    exponentiate = TRUE,
    tidy_fun = function(...) td
  ) %>%
    gtsummary::modify_caption(
      paste0("**Survey-weighted Cox model with polypharmacy Ã— ", flag, " (0-meds excluded)**")
    ) %>%
    gtsummary::bold_labels()
})
sink()

# print interaction tables
int_tbls[[1]]
int_tbls[[2]]
int_tbls[[3]]
int_tbls[[4]]

# -------------------------------------------------------------------
# Collect all combo HRs for plotting
# -------------------------------------------------------------------
plot_dat <- purrr::imap_dfr(int_measures, function(obj, flag) {
  obj$combos %>%
    dplyr::mutate(flag = flag, .before = 1)
})

# -------------------------------------------------------------------
# plot HRs for all combos & classes
# -------------------------------------------------------------------
# make nicer labels for the combos
plot_dat_clean <- plot_dat %>%
  dplyr::mutate(
    combo_lbl = dplyr::case_when(
      combo == "poly1_4_class0"  ~ "1â€“4 meds, Non-user",
      combo == "poly1_4_class1"  ~ "1â€“4 meds, User",
      combo == "poly5_9_class0"  ~ "5â€“9 meds, Non-user",
      combo == "poly5_9_class1"  ~ "5â€“9 meds, User",
      combo == "poly10p_class0"  ~ "â‰¥10 meds, Non-user",
      combo == "poly10p_class1"  ~ "â‰¥10 meds, User",
      TRUE ~ combo
    ),
    # Create clean names for the drug classes (for Facet Headers)
    flag_clean = dplyr::case_when(
      flag == "rx_antineoplastic" ~ "Antineoplastic Agents",
      flag == "rx_cns"            ~ "CNS Agents",
      flag == "rx_cardiovascular" ~ "Cardiovascular Agents",
      flag == "rx_psychotherapeutic" ~ "Psychotherapeutic Agents",
      TRUE ~ flag
    ),
    # order from lowest exposure to highest, and non-user before user
    combo_lbl = factor(
      combo_lbl,
      levels = c(
        "1â€“4 meds, Non-user",
        "1â€“4 meds, User",
        "5â€“9 meds, Non-user",
        "5â€“9 meds, User",
        "â‰¥10 meds, Non-user",
        "â‰¥10 meds, User"
      )
    )
  )

# Faceted Plot by Therapeutic Class
ggplot(plot_dat_clean,
       aes(y = combo_lbl, x = HR, xmin = LCL, xmax = UCL, color = combo_lbl)) +
  geom_pointrange(position = position_dodge(width = 0.6)) +
  geom_vline(xintercept = 1, linetype = 2, color = "grey40") +
  scale_x_log10(breaks = c(0.5, 1, 2, 4, 8)) +
  labs(
    title = "Hazard ratios for polypharmacy by therapeutic class",
    subtitle = "Interaction models (0 medications excluded); Faceted by Class",
    x     = "Hazard ratio (log scale)",
    y     = "",
    color = "Medication Status"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "none",
    strip.text = element_text(face = "bold", size = 11),
    panel.grid.minor = element_blank()
  ) +
  facet_wrap(~ flag_clean, scales = "free_y", ncol = 2)

# RERI / multiplicative table
#--------------------------------------------------
reri_tbl <- purrr::imap_dfr(int_measures, ~{
    if (is.null(.x$im) || nrow(.x$im) == 0) return(NULL)
    .x$im %>% dplyr::mutate(flag = .y, .before = 1)
})

reri_tbl
```

\\newpage

# **Sensitivity: continuous medication count with spline**

To assess whether the categorical groupings (0, 1-4, 5-9, â‰¥10) adequately capture the dose-response relationship, we fit a model using a restricted cubic spline for continuous medication count. This flexible approach allows us to visualize potential non-linear associations without imposing arbitrary cut-points. We use a natural spline with 2 degrees of freedom (equivalent to 3 knots), which provides flexibility while avoiding overfitting.

```{r spline-analysis}
# -------------------------------------------------------------------------
# 1. turn each imputed dataset into a survey design  ==> design_list
#    assumes you already have `imp` (class mids) from mice()
# -------------------------------------------------------------------------
comp_list <- lapply(seq_len(imp$m), function(i) {
  di <- mice::complete(imp, i)

  di %>%
    dplyr::mutate(
      age_cat       = mk_age_cat(ridageyr),
      indfmpir_cat  = mk_indfmpir_cat(indfmpir),
      insured       = factor(insured, levels = c("No","Yes")),
      poly_cat      = factor(poly_cat, levels = c("1â€“4","0","5â€“9","â‰¥10")),
      comorbidity_n = as.numeric(comorbidity_n),
      cci_score     = as.numeric(cci_score)
    )
})

design_list <- lapply(comp_list, function(di) {
  svydesign(
    ids     = ~ sdmvpsu,
    strata  = ~ sdmvstra,
    weights = ~ wtint_pool,
    nest    = TRUE,
    data    = di
  )
})

# -------------------------------------------------------------------------
# 2. fit the spline model on EACH design
# -------------------------------------------------------------------------
fit_list <- lapply(design_list, function(dd) {
  # make sure insured is 2-level factor in the design
  dd <- update(dd, insured = factor(insured, levels = c("No", "Yes")))

  svycoxph(
    survival::Surv(time_y, event) ~ splines::ns(rxdcount, knots = c(5, 10)) +
      age_cat + sex + race_eth + ed_cat + indfmpir_cat + insured +
      comorbidity_n + cci_score + visits_cat + hosp_stays_cat,
    design = dd
  )
})

# -------------------------------------------------------------------------
# 3. pool spline coefficients (mitools) and build prediction grid
# -------------------------------------------------------------------------
coefs <- lapply(fit_list, coef)
vcovs <- lapply(fit_list, vcov)
mi_pool <- mitools::MIcombine(coefs, vcovs)
beta    <- mi_pool$coefficients
V       <- mi_pool$variance
coef_nm <- names(beta)

# use the first design as reference for factor levels
d1  <- design_list[[1]]
dat1 <- d1$variables

# survey-based reference profile
svy_median <- function(des, var) {
  q <- svyquantile(as.formula(paste0("~", var)), des,
                           quantiles = 0.5, na.rm = TRUE, ci = FALSE)
  as.numeric(coef(q))
}
svy_mode <- function(des, var) {
  tb <- svytable(as.formula(paste0("~", var)), des)
  nm <- names(tb); nm[which.max(as.numeric(tb))]
}

ref_age_cat_val    <- svy_mode(d1, "age_cat")
ref_sex_val        <- svy_mode(d1, "sex")
ref_race_val       <- svy_mode(d1, "race_eth")
ref_ed_val         <- svy_mode(d1, "ed_cat")
ref_pir_val        <- svy_mode(d1, "indfmpir_cat")
ref_ins_val        <- svy_mode(d1, "insured")
ref_visits_val     <- svy_mode(d1, "visits_cat")
ref_hosp_val       <- svy_mode(d1, "hosp_stays_cat")
ref_comorb         <- svy_median(d1, "comorbidity_n")
ref_cci            <- svy_median(d1, "cci_score")

pred_base <- tibble::tibble(
  rxdcount      = 0,
  age_cat       = factor(ref_age_cat_val,   levels = levels(dat1$age_cat)),
  sex           = factor(ref_sex_val,       levels = levels(dat1$sex)),
  race_eth      = factor(ref_race_val,      levels = levels(dat1$race_eth)),
  ed_cat        = factor(ref_ed_val,        levels = levels(dat1$ed_cat)),
  indfmpir_cat  = factor(ref_pir_val,       levels = levels(dat1$indfmpir_cat)),
  insured       = factor(ref_ins_val,       levels = levels(dat1$insured)),
  comorbidity_n = ref_comorb,
  cci_score     = ref_cci,
  visits_cat    = factor(ref_visits_val,    levels = levels(dat1$visits_cat)),
  hosp_stays_cat= factor(ref_hosp_val,      levels = levels(dat1$hosp_stays_cat))
)

pred_grid <- pred_base %>%
  dplyr::slice(rep(1, 26)) %>%
  dplyr::mutate(rxdcount = 0:25)

TT_full <- terms(fit_list[[1]])
TT_noy  <- delete.response(TT_full)

mf_grid <- model.frame(TT_noy, data = pred_grid,
                       xlev = fit_list[[1]]$xlevels,
                       na.action = na.pass)

X <- model.matrix(TT_noy, mf_grid)
X <- X[, coef_nm, drop = FALSE]

# HRs relative to 0 meds
X_ref <- X[1, , drop = FALSE]
Delta <- X - matrix(X_ref, nrow = nrow(X), ncol = ncol(X), byrow = TRUE)
lp    <- as.vector(Delta %*% beta)
se_lp <- sqrt(pmax(0, rowSums((Delta %*% V) * Delta)))

pred_df <- pred_grid %>%
  dplyr::mutate(
    HR  = exp(lp),
    LCL = exp(lp - 1.96 * se_lp),
    UCL = exp(lp + 1.96 * se_lp)
  )

ggplot2::ggplot(pred_df, aes(x = rxdcount, y = HR)) +
  ggplot2::geom_ribbon(aes(ymin = LCL, ymax = UCL), alpha = 0.2) +
  ggplot2::geom_line(linewidth = 1) +
  ggplot2::geom_hline(yintercept = 1, linetype = 2, color = "grey50") +
  ggplot2::scale_y_continuous(trans = "log10",
                              breaks = c(0.5, 1, 2, 3, 5, 10)) +
  ggplot2::labs(
    title = "Adjusted HR vs medication count (MI pooled spline)",
    subtitle = "Natural cubic spline, knots at 5 and 10",
    x = "Medication count",
    y = "Hazard Ratio (log scale)"
  ) +
  ggplot2::theme_minimal(base_size = 12) +
  ggplot2::theme(panel.grid.minor = element_blank())
```

\\newpage

# **Sensitivity: restrict to higher multimorbidity thresholds**

To address potential confounding by indication, we conduct sensitivity analyses restricting the sample to individuals with at least 2, 3, 4, or 5 chronic conditions. This approach helps isolate the effect of polypharmacy from underlying disease burden, as individuals with more comorbidities have more legitimate clinical reasons for taking multiple medications. If the polypharmacy-mortality association persists or strengthens in these restricted samples, it suggests the relationship is not solely due to confounding by indication.

```{r multimorbidity, fig.width=7, fig.height=5}
cutpoints <- c(2,3,4,5)

tidy_poly <- function(mira_obj, model_name) {
  po <- mice::pool(mira_obj)
  sm <- summary(po, conf.int = TRUE)
  sm %>%
    dplyr::filter(grepl("^poly_cat", term)) %>%
    dplyr::transmute(
      model = model_name,
      term,
      HR   = exp(estimate),
      LCL  = exp(`2.5 %`),
      UCL  = exp(`97.5 %`)
    )
}

fit_mm <- lapply(cutpoints, function(k) {
  with(imp, {
    di <- tibble(
      sdmvpsu, sdmvstra, wtint_pool, time_y, event, ridageyr,
      poly_cat = factor(poly_cat, levels = c("1â€“4","0","5â€“9","â‰¥10")),
      age_cat  = mk_age_cat(ridageyr),
      sex, race_eth, ed_cat,
      insured = factor(insured, levels = c("No","Yes")),
      indfmpir, indfmpir_cat = mk_indfmpir_cat(indfmpir),
      comorbidity_n = as.numeric(comorbidity_n),
      cci_score     = as.numeric(cci_score),
      visits_cat, hosp_stays_cat
    ) %>%
      dplyr::filter(comorbidity_n >= k) %>%
      dplyr::mutate(dplyr::across(where(is.factor), forcats::fct_drop))

    dd <- svydesign(
      ids     = ~ sdmvpsu,
      strata  = ~ sdmvstra,
      weights = ~ wtint_pool,
      nest    = TRUE,
      data    = di
    )

    svycoxph(
      Surv(time_y, event) ~ poly_cat + age_cat + sex + race_eth +
        ed_cat + indfmpir_cat + insured + comorbidity_n + cci_score +
        visits_cat + hosp_stays_cat,
      design = dd
    )
  })
})

sink(tempfile())

mm_pooled <- purrr::map2_dfr(fit_mm, cutpoints, function(mira_obj, k) {
  tidy_poly(mira_obj, paste0("Comorbidity â‰¥ ", k))
})

sink()

y_order <- unique(mm_pooled$model)

mm_plot <- mm_pooled %>%
    mutate(
        exposure_lbl = case_when(
            term == "poly_cat5â€“9"  ~ "5â€“9 medications",
            term == "poly_catâ‰¥10"  ~ "â‰¥10 medications",
            term == "poly_cat1â€“4"  ~ "1â€“4 medications (ref)",
            term == "poly_cat0"    ~ "0 medications",
            TRUE                   ~ term
        ),
        .keep = "all"
    ) %>%
    filter(exposure_lbl != "1â€“4 medications (ref)") %>%
    mutate(
        model = fct_rev(fct_inorder(model)),
        exposure_lbl = factor(exposure_lbl,
                              levels = c("0 medications", "5â€“9 medications", "â‰¥10 medications"))
    )

ggplot(mm_plot,
       aes(x = HR, y = model,
           xmin = LCL, xmax = UCL,
           color = exposure_lbl)) +
    geom_pointrange(position = position_dodge2(width = 0.6)) +
    geom_vline(xintercept = 1, linetype = 2, color = "gray50") +
    scale_x_log10() +
    scale_y_discrete(limits = y_order) +
    labs(
        title = "Polypharmacy HRs across increasing multimorbidity restrictions",
        x     = "Hazard ratio",
        y     = "",
        color = "Medication category"
    ) +
    theme_minimal(base_size = 12) +
    theme(
        legend.position = "right"
    )
```

\\newpage

# **Sensitivity: censor follow-up at 5 and 10 years**

We conduct sensitivity analyses censoring follow-up at 5 and 10 years to assess whether the polypharmacy-mortality association differs by duration of follow-up. Shorter follow-up windows may better capture acute medication-related risks, while longer follow-up may be more affected by changes in medication use over time (not captured by our baseline measurement). These analyses also reduce the potential for exposure misclassification that increases with time since baseline.

```{r censor-5}

fit_5yr <- with(imp, {
  di <- tibble(
    sdmvpsu, sdmvstra, wtint_pool, time_y, event, ridageyr,
    poly_cat = factor(poly_cat, levels = c("1â€“4","0","5â€“9","â‰¥10")),
    age_cat  = mk_age_cat(ridageyr),
    sex, race_eth, ed_cat,
    insured = factor(insured, levels = c("No","Yes")),
    indfmpir, indfmpir_cat = mk_indfmpir_cat(indfmpir),
    comorbidity_n = as.numeric(comorbidity_n),
    cci_score     = as.numeric(cci_score),
    visits_cat, hosp_stays_cat
  ) %>%
    mutate(
      time_y_5 = pmin(time_y, 5),
      event_5  = ifelse(time_y <= 5 & event == 1, 1, 0)
    ) %>%
    mutate(across(where(is.factor), fct_drop))

  dd <- svydesign(
    ids     = ~ sdmvpsu,
    strata  = ~ sdmvstra,
    weights = ~ wtint_pool,
    nest    = TRUE,
    data    = di
  )

  svycoxph(
    Surv(time_y_5, event_5) ~ poly_cat + age_cat + sex + race_eth +
      ed_cat + indfmpir_cat + insured + comorbidity_n + cci_score +
      visits_cat + hosp_stays_cat,
    design = dd
  )
})
```

```{r censor-10}
fit_10yr <- with(imp, {
  di <- tibble(
    sdmvpsu, sdmvstra, wtint_pool, time_y, event, ridageyr,
    poly_cat = factor(poly_cat, levels = c("1â€“4","0","5â€“9","â‰¥10")),
    age_cat  = mk_age_cat(ridageyr),
    sex, race_eth, ed_cat,
    insured = factor(insured, levels = c("No","Yes")),
    indfmpir, indfmpir_cat = mk_indfmpir_cat(indfmpir),
    comorbidity_n = as.numeric(comorbidity_n),
    cci_score     = as.numeric(cci_score),
    visits_cat, hosp_stays_cat
  ) %>%
    mutate(
      time_y_10 = pmin(time_y, 10),
      event_10  = ifelse(time_y <= 10 & event == 1, 1, 0)
    ) %>%
    mutate(across(where(is.factor), fct_drop))

  dd <- svydesign(
    ids     = ~ sdmvpsu,
    strata  = ~ sdmvstra,
    weights = ~ wtint_pool,
    nest    = TRUE,
    data    = di
  )

  svycoxph(
    Surv(time_y_10, event_10) ~ poly_cat + age_cat + sex + race_eth +
      ed_cat + indfmpir_cat + insured + comorbidity_n + cci_score +
      visits_cat + hosp_stays_cat,
    design = dd
  )
})
```

\\newpage

# **Sensitivity: remove anti-biotics from the prescription medication count**

We conduct sensitivity analyses taking anti-biotics out of the prescription medication count. This involves manually counting the number of prescription medications, rather than using the supplied number of medications provided in the data. The rationale for removing anti-biotics is that these are used in the short-term. It does not necessarily reflect chronic or persistent medication burden, and may be slightly different from the "other" prescription medications included in the count.

```{r exclude antibiotics from med count}

fit_noabx <- with(imp, {
  di <- tibble(
    sdmvpsu, sdmvstra, wtint_pool, time_y, event,
    poly_cat_no_abx = factor(poly_cat_no_abx, levels = c("1â€“4","0","5â€“9","â‰¥10")),
    age_cat  = mk_age_cat(ridageyr),
    sex, race_eth, ed_cat,
    insured  = factor(insured, levels = c("No","Yes")),
    indfmpir, indfmpir_cat = mk_indfmpir_cat(indfmpir),
    comorbidity_n = as.numeric(comorbidity_n),
    cci_score     = as.numeric(cci_score),
    visits_cat, hosp_stays_cat
  ) %>%
    mutate(across(where(is.factor), fct_drop))
  dd <- svydesign(ids = ~sdmvpsu, strata = ~sdmvstra, weights = ~wtint_pool,
                  nest = TRUE, data = di)
  svycoxph(
    Surv(time_y, event) ~ poly_cat_no_abx + age_cat + sex + race_eth +
      ed_cat + indfmpir_cat + insured + comorbidity_n + cci_score +
      visits_cat + hosp_stays_cat,
    design = dd
  )
})

```

\\newpage

# **Grand forest plot (main + censoring + multimorbidity)**

We synthesize results from all model specifications in a comprehensive forest plot using a "Table-Plot" visualization style. This includes results from the main models (Crude and Full), censoring sensitivity analyses, multimorbidity restrictions, and the sensitivity analysis removing antibiotics.

```{r grand-forest, fig.width=9, fig.height=10}
tidy_poly_model <- function(mira_obj, model_name) {
    po <- mice::pool(mira_obj)
    sm <- summary(po, conf.int = TRUE)
    sm %>%
        dplyr::filter(grepl("^poly_cat", term)) %>%
        dplyr::transmute(
            model = model_name,
            term,
            estimate = exp(estimate), # HR
            ci.lower = exp(`2.5 %`),
            ci.upper = exp(`97.5 %`)
        )
}

sink(tempfile())

df_crude <- tidy_poly_model(fit_crude, "Crude Model")
df_full  <- tidy_poly_model(fit_full,  "Full Model")
df_5     <- tidy_poly_model(fit_5yr,   "Sensitivity: 5-year censor")
df_10    <- tidy_poly_model(fit_10yr,  "Sensitivity: 10-year censor")
df_noabx <- tidy_poly_model(fit_noabx, "Sensitivity: No antibiotics")

# Reformat MM pool to match
df_mm <- mm_pooled %>%
  dplyr::rename(estimate = HR, ci.lower = LCL, ci.upper = UCL) %>%
  dplyr::select(model, term, estimate, ci.lower, ci.upper)

sink()

# 1. Combine all results (excluding Basic Model)
all_res <- bind_rows(
    df_crude,
    df_full,
    df_mm,
    df_5,
    df_10,
    df_noabx
)

# 2. Format the data frame for the specific visualization style
df_plot <- all_res %>%
  # Create a clean label for the exposure levels
  mutate(
    exp.label = case_when(
        term %in% c("poly_cat0", "poly_cat_no_abx0") ~ "0 medications",
        term %in% c("poly_cat5â€“9", "poly_cat_no_abx5â€“9") ~ "5â€“9 medications",
        term %in% c("poly_catâ‰¥10", "poly_cat_no_abxâ‰¥10") ~ "â‰¥10 medications",
        TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(exp.label)) %>%
  # Create the label string "HR (95% CI)"
  mutate(
    est.label = sprintf('%.2f (%.2f, %.2f)', estimate, ci.lower, ci.upper)
  )

# 3. Create a list of data frames, one per model, inserting a Header Row for each
model_list <- unique(df_plot$model)
final_df_list <- list()

for(m in model_list) {
  # Get rows for this model
  sub_df <- df_plot %>% filter(model == m)
  
  # Create a header row
  header_row <- tibble(
    model = m,
    exp.label = m,  # Use model name as label
    est.label = "", # Empty for header
    estimate = NA, ci.lower = NA, ci.upper = NA,
    is.header = TRUE
  )
  
  # Bind header + rows
  combined <- bind_rows(header_row, sub_df %>% mutate(is.header = FALSE))
  final_df_list[[m]] <- combined
}

# Bind everything together
df_viz <- bind_rows(final_df_list)

# 4. Add the absolute top header (like the example's "Exposure / OR (CI)")
# Note: In the example, this was row 1.
top_header <- tibble(
  model = "Header",
  exp.label = "Model / Exposure",
  est.label = "HR (95% CI)",
  estimate = NA, ci.lower = NA, ci.upper = NA,
  is.header = TRUE
)

df_viz <- bind_rows(top_header, df_viz)

# 5. Add formatting helpers and Grouping Variable for Color/Shape
df_viz <- df_viz %>%
  mutate(.i = row_number()) %>%
  mutate(index = fct_rev(factor(.i))) %>% 
  mutate(.fontface = ifelse(is.header, 'bold', 'plain')) %>%
  mutate(.fontsize = 12 * 0.36) %>%
  # Create a grouping variable for aesthetics. 
  # If it is a header row, we label it "Header" to hide it later.
  mutate(exposure_group = ifelse(is.header, "Header", exp.label)) %>%
  # Set factor levels to ensure consistent ordering in legend/scales
  mutate(exposure_group = factor(exposure_group, 
                                 levels = c("0 medications", "5â€“9 medications", "â‰¥10 medications", "Header")))

# 6. Plot
plot.forest <- df_viz %>%
  ggplot(aes(y = index, x = estimate)) +
  
  # --- Forest plot points and lines ---
  geom_errorbar(aes(xmin = ci.lower, xmax = ci.upper, color = exposure_group), 
                width = 0.25, linewidth = 0.8, na.rm = TRUE) +
  geom_point(aes(color = exposure_group, shape = exposure_group), 
             size = 3.5, na.rm = TRUE) +
  
  # --- Manual Scales for Color and Shape ---
  # 'breaks' argument controls what appears in the legend (we exclude "Header")
  scale_color_manual(
    name = "Exposure Group",
    values = c(
      "0 medications"   = "#D55E00",  # Vermilion
      "5â€“9 medications" = "#0072B2",  # Blue
      "â‰¥10 medications" = "#CC79A7",  # Reddish Purple
      "Header"          = "transparent" 
    ),
    breaks = c("0 medications", "5â€“9 medications", "â‰¥10 medications")
  ) +
  scale_shape_manual(
    name = "Exposure Group",
    values = c(
      "0 medications"   = 16, # Circle
      "5â€“9 medications" = 15, # Square
      "â‰¥10 medications" = 17, # Triangle
      "Header"          = NA
    ),
    breaks = c("0 medications", "5â€“9 medications", "â‰¥10 medications")
  ) +
  
  # --- Axis formatting ---
  xlab('\nHazard Ratio (log scale)') +
  scale_x_log10(breaks = c(0.5, 1.0, 2.0, 4.0)) +
  coord_cartesian(xlim = c(0.05, 6), clip = 'off') +
  
  # --- Reference line ---
  geom_vline(xintercept = 1, linetype = 'dashed', color = "gray40") +
  
  # --- Text Labels (Table columns) ---
  geom_text(aes(x = 0.05, label = exp.label, fontface = .fontface), 
            hjust = 0, size = 3.5, color = "black") + 
  geom_text(aes(x = 0.25, label = est.label, fontface = .fontface), 
            hjust = 0, size = 3.5, color = "black") +
  
  # --- Theme ---
  theme_classic() +
  theme(
    legend.position = 'right', # Position legend on the right
    legend.title = element_text(face = "bold"),
    axis.line = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_text(size = 10),
    axis.title.x = element_text(size = 12, face = 'bold', hjust = 0.6),
    plot.margin = margin(t=10, r=10, b=10, l=10)
  ) +
  # Bottom axis line segment
  annotate(geom = 'segment', x = 0.5, xend = 4, y = 0, lwd = 0.75)

plot.forest
```